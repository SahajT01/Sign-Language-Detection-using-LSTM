# Sign-Language-Detection-using-LSTM

We propose a real-time sign language detection system using Long Short-Term Memory (LSTM) networks in this research paper. Sign language is a complex and dynamic language used by the deaf and hard-of-hearing communities to communicate with one another and the rest of the world. The proposed system is intended to help people with hearing impairments by converting sign language into text or speech in real-time. A camera records video of the user gesturing various signs, which is then processed by the LSTM network to identify the corresponding word associated with that gesture. The proposed method uses matplot and mediapipe libraries of Python to draw and track the key points in the video made while gesturing the sign.  The LSTM network is trained using a large dataset of sign language videos to improve the system's accuracy. The results demonstrate that the proposed method has a high degree of accuracy and is capable of real-time detection of sign language. Moreover, this research could provide a valuable communication tool for the deaf and hard-of-hearing community, and could also be extended to other applications such as human-robot interaction, virtual reality, and gaming.

